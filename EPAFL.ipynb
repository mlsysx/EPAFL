{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "abkeYflwBmJL"
      },
      "outputs": [],
      "source": [
        "!pip install -q pytorch-msssim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lcb8TvNTzI7-"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import ticker\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import pickle\n",
        "import PIL.Image as Image\n",
        "from pytorch_msssim import ssim\n",
        "from matplotlib import rc\n",
        "import csv\n",
        "from os.path import join as oj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ziwr-D0HBtQM"
      },
      "outputs": [],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = 'cuda' if use_cuda else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvQAZs4BgI-Z"
      },
      "outputs": [],
      "source": [
        "import torch.distributions as dist\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, channel=3, hideen=768, num_classes=10):\n",
        "        super(LeNet, self).__init__()\n",
        "        act = nn.Sigmoid\n",
        "        self.body = nn.Sequential(\n",
        "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
        "            act(),\n",
        "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
        "            act(),\n",
        "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
        "            act(),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hideen, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.body(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    try:\n",
        "        if hasattr(m, \"weight\"):\n",
        "            m.weight.data.uniform_(-0.5, 0.5)\n",
        "\n",
        "    except Exception:\n",
        "        print('warning: failed in weights_init for %s.weight' % m._get_name())\n",
        "\n",
        "    try:\n",
        "        if hasattr(m, \"bias\"):\n",
        "            m.bias.data.uniform_(-0.5, 0.5)\n",
        "\n",
        "    except Exception:\n",
        "        print('warning: failed in weights_init for %s.bias' % m._get_name())\n",
        "\n",
        "\n",
        "def main():\n",
        "    dataset = 'cifar10'\n",
        "    root_path = '.'\n",
        "    data_path = os.path.join(root_path, '../data').replace('\\\\', '/')\n",
        "    save_path = os.path.join(root_path, 'results/EPAFL_%s'%dataset).replace('\\\\', '/')\n",
        "\n",
        "    lr = 1.0\n",
        "    num_dummy = 1\n",
        "    Iteration = 300\n",
        "    num_exp = 100\n",
        "    threshold = 0.001\n",
        "    patience = 15\n",
        "\n",
        "    succ_rec_img = 0\n",
        "    succ_rec_label = 0\n",
        "    all_succ_loss = []\n",
        "    all_succ_mse = []\n",
        "    all_succ_ssim = []\n",
        "    all_succ_iters = []\n",
        "    all_loss = []\n",
        "    all_mse = []\n",
        "    all_ssim = []\n",
        "    all_iters = []\n",
        "    train_iters = 0\n",
        "    all_time = []\n",
        "    all_succ_time = []\n",
        "\n",
        "\n",
        "    tt = transforms.Compose([transforms.ToTensor()])\n",
        "    tp = transforms.Compose([transforms.ToPILImage()])\n",
        "\n",
        "    print(dataset, 'root_path:', root_path)\n",
        "    print(dataset, 'data_path:', data_path)\n",
        "    print(dataset, 'save_path:', save_path)\n",
        "\n",
        "    if not os.path.exists('results'):\n",
        "        os.mkdir('results')\n",
        "    if not os.path.exists(save_path):\n",
        "        os.mkdir(save_path)\n",
        "\n",
        "\n",
        "    # load data\n",
        "    if dataset == 'MNIST':\n",
        "        shape_img = (28, 28)\n",
        "        num_classes = 10\n",
        "        channel = 1\n",
        "        hidden = 588\n",
        "        dst = datasets.MNIST(data_path, download=True)\n",
        "\n",
        "    elif dataset == 'cifar10':\n",
        "        shape_img = (32, 32)\n",
        "        num_classes = 10\n",
        "        channel = 3\n",
        "        hidden = 768\n",
        "        dst = datasets.CIFAR10(data_path, download=True)\n",
        "\n",
        "    else:\n",
        "        exit('unknown dataset')\n",
        "\n",
        "    np.random.seed(42)\n",
        "    idx_shuffle = np.random.permutation(len(dst))\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    for idx_net in range(num_exp):\n",
        "\n",
        "        best_val_loss = None\n",
        "        wait = 0\n",
        "        early_stop = False\n",
        "        net = LeNet(channel=channel, hideen=hidden, num_classes=num_classes)\n",
        "        net.apply(weights_init)\n",
        "\n",
        "        print('running %d|%d experiment'%(idx_net, num_exp))\n",
        "        net = net.to(device)\n",
        "\n",
        "        print('Try to generate %d images' % (num_dummy))\n",
        "\n",
        "        criterion = nn.CrossEntropyLoss().to(device)\n",
        "        imidx_list = []\n",
        "\n",
        "        for imidx in range(num_dummy):\n",
        "            idx = idx_shuffle[idx_net]\n",
        "            imidx_list.append(idx)\n",
        "            tmp_datum = tt(dst[idx][0]).float().to(device)\n",
        "            tmp_datum = tmp_datum.view(1, *tmp_datum.size())\n",
        "            tmp_label = torch.Tensor([dst[idx][1]]).long().to(device)\n",
        "            tmp_label = tmp_label.view(1, )\n",
        "            if imidx == 0:\n",
        "                gt_data = tmp_datum\n",
        "                gt_label = tmp_label\n",
        "            else:\n",
        "                gt_data = torch.cat((gt_data, tmp_datum), dim=0)\n",
        "                gt_label = torch.cat((gt_label, tmp_label), dim=0)\n",
        "\n",
        "\n",
        "        # compute original gradient\n",
        "        out = net(gt_data)\n",
        "        y = criterion(out, gt_label)\n",
        "        dy_dx = torch.autograd.grad(y, net.parameters())\n",
        "        original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
        "\n",
        "        # generate dummy data and label\n",
        "        dummy_data = torch.randn(gt_data.size()).to(device).requires_grad_(True)\n",
        "        dummy_label = torch.randn((gt_data.shape[0], num_classes)).to(device).requires_grad_(True)\n",
        "\n",
        "        optimizer = torch.optim.LBFGS([dummy_data, ], lr=lr)\n",
        "        # predict the ground-truth label\n",
        "        label_pred = torch.argmin(torch.sum(original_dy_dx[-2], dim=-1), dim=-1).detach().reshape((1,)).requires_grad_(False)\n",
        "\n",
        "\n",
        "        history = []\n",
        "        history_iters = []\n",
        "        losses = []\n",
        "        mses = []\n",
        "        ssims = []\n",
        "\n",
        "        iter_start_time = time.time()\n",
        "        for iters in range(Iteration):\n",
        "\n",
        "            def closure():\n",
        "                optimizer.zero_grad()\n",
        "                pred = net(dummy_data)\n",
        "                dummy_loss = criterion(pred, label_pred)\n",
        "\n",
        "                dummy_dy_dx = torch.autograd.grad(dummy_loss, net.parameters(), create_graph=True)\n",
        "\n",
        "                grad_diff = 0\n",
        "                for gx, gy in zip(dummy_dy_dx, original_dy_dx):\n",
        "\n",
        "                    #Euclidean distance\n",
        "                    grad_diff += ((gx - gy) ** 2).sum()\n",
        "\n",
        "                grad_diff.backward()\n",
        "                return grad_diff\n",
        "\n",
        "            optimizer.step(closure)\n",
        "            current_loss = closure().item()\n",
        "\n",
        "            losses.append(current_loss)\n",
        "            mean = torch.mean((dummy_data-gt_data)**2).item()\n",
        "            mses.append(mean)\n",
        "            s = ssim(dummy_data,torch.unsqueeze(gt_data[0],dim=0),data_range=0).item()\n",
        "            ssims.append(s)\n",
        "\n",
        "            if (iters+1) % 10 == 0:\n",
        "\n",
        "                current_time = str(time.strftime(\"[%Y-%m-%d %H:%M:%S]\", time.localtime()))\n",
        "                print(current_time, iters, 'loss = %.8f, mse = %.8f, ssim = %.8f' %(current_loss, mses[-1], ssims[-1]))\n",
        "\n",
        "                history.append([tp(dummy_data[imidx].cpu()) for imidx in range(num_dummy)])\n",
        "                history_iters.append(iters)\n",
        "\n",
        "\n",
        "                for imidx in range(num_dummy):\n",
        "                    plt.figure(figsize=(12, 8))\n",
        "                    plt.subplot(5, 10, 1)\n",
        "                    plt.imshow(tp(gt_data[imidx].cpu()))\n",
        "                    plt.title('Ground truth')\n",
        "                    plt.axis('off')\n",
        "                    for i in range(min(len(history), 29)):\n",
        "                        plt.subplot(5, 10, i + 2)\n",
        "                        plt.imshow(history[i][imidx])\n",
        "                        plt.title('iter=%d' % (history_iters[i]+1))\n",
        "                        plt.axis('off')\n",
        "                    plt.savefig('%s/EPAFL_on_%s_%05d.png' % (save_path, imidx_list, imidx_list[imidx]))\n",
        "                    plt.close()\n",
        "\n",
        "\n",
        "            #detectplateau\n",
        "\n",
        "            if best_val_loss is None or current_loss < best_val_loss:\n",
        "              best_val_loss = current_loss\n",
        "              wait = 0\n",
        "\n",
        "              #Threshold\n",
        "\n",
        "              if current_loss < threshold:\n",
        "                  print('Iteration required: ', iters+1)\n",
        "\n",
        "                  train_iters = iters+1\n",
        "                  early_stop = True\n",
        "\n",
        "                  break # converge\n",
        "\n",
        "            elif wait >= patience:\n",
        "\n",
        "              print('Iteration required: ', iters+1)\n",
        "\n",
        "              train_iters = iters+1\n",
        "              early_stop = True\n",
        "\n",
        "              break # converge\n",
        "\n",
        "            else:\n",
        "              wait += 1\n",
        "\n",
        "\n",
        "\n",
        "        all_time.append(time.time()-iter_start_time)\n",
        "\n",
        "        pred_label = label_pred.item()\n",
        "\n",
        "        l = gt_label.detach().cpu().data\n",
        "\n",
        "\n",
        "        if not early_stop:\n",
        "          train_iters = Iteration\n",
        "\n",
        "\n",
        "        print('imidx_list:', imidx_list)\n",
        "        print('loss:', losses[-1])\n",
        "        print('mse:', mses[-1])\n",
        "        print('ssim:', ssims[-1])\n",
        "        print('gt_label:', l.item(), 'pred_label:', pred_label)\n",
        "\n",
        "        all_loss.append(losses[-1])\n",
        "        all_mse.append(mses[-1])\n",
        "        all_ssim.append(ssims[-1])\n",
        "        all_iters.append(train_iters)\n",
        "\n",
        "        if l == pred_label:\n",
        "          succ_rec_label += 1\n",
        "\n",
        "        if ssims[-1] > 0.9:\n",
        "          succ_rec_img += 1\n",
        "          all_succ_loss.append(losses[-1])\n",
        "          all_succ_mse.append(mses[-1])\n",
        "          all_succ_ssim.append(ssims[-1])\n",
        "          all_succ_iters.append(train_iters)\n",
        "          all_succ_time.append(all_time[-1])\n",
        "\n",
        "\n",
        "        print('----------------------\\n\\n')\n",
        "\n",
        "\n",
        "    folder = oj('results',\n",
        "\t\t\t\tdataset,\n",
        "\t\t\t\t\"plateau+threshold\",\n",
        "\t\t\t\t'p={}_th={}'.format(str(patience),str(threshold)))\n",
        "\n",
        "\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    with open(oj(folder, 'results.txt'), 'w') as file:\n",
        "      file.write('ASRl = '+ str((succ_rec_label * 100) / 100) + '\\n' )\n",
        "      file.write('ASRc = '+ str((succ_rec_img * 100) / 100) + '\\n')\n",
        "      file.write('All Total time = '+ str(np.sum(all_time)) + '\\n')\n",
        "      file.write('All Loss = '+ str(np.average(all_loss)) + '\\n')\n",
        "      file.write('All MSE = '+ str(np.average(all_mse)) + '\\n')\n",
        "      file.write('All SSIM = ' + str(np.average(all_ssim)) + '\\n')\n",
        "      file.write('All Max iteration = ' + str(np.max(all_iters)) + '\\n')\n",
        "      file.write('All Min iteration = '+ str(np.min(all_iters)) + '\\n')\n",
        "      file.write('All Average iteration = '+ str(np.average(all_iters))+ '\\n')\n",
        "      file.write('All Stand. dev. iteration = '+ str(np.std(all_iters))+ '\\n\\n')\n",
        "\n",
        "      file.write('Succ Total time = '+ str(np.sum(all_succ_time))+ '\\n')\n",
        "      file.write('Succ Loss = '+ str(np.average(all_succ_loss))+ '\\n')\n",
        "      file.write('Succ MSE = '+ str(np.average(all_succ_mse))+ '\\n')\n",
        "      file.write('Succ SSIM = '+ str(np.average(all_succ_ssim))+ '\\n')\n",
        "      file.write('Succ Max iteration = '+ str(np.max(all_succ_iters))+ '\\n')\n",
        "      file.write('Succ Min iteration = '+ str(np.min(all_succ_iters))+ '\\n')\n",
        "      file.write('Succ Average iteration = '+ str(np.average(all_succ_iters))+ '\\n')\n",
        "      file.write('Succ Stand. dev. iteration = '+ str(np.std(all_succ_iters))+ '\\n\\n')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}